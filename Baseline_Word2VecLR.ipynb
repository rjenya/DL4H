{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50024b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = \"./resource\"\n",
    "# set seed\n",
    "seed = 24\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "494365d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def save_pkl(path, obj):\n",
    "  with open(path, 'wb') as f:\n",
    "    pickle.dump(obj, f)\n",
    "    print(\" [*] save %s\" % path)\n",
    "\n",
    "def load_pkl(path):\n",
    "  with open(path,'rb') as f:\n",
    "    obj = pickle.load(f)\n",
    "    print(\" [*] load %s\" % path)\n",
    "    return obj\n",
    "\n",
    "def save_npy(path, obj):\n",
    "  np.save(path, obj)\n",
    "  print(\" [*] save %s\" % path)\n",
    "\n",
    "def load_npy(path):\n",
    "  obj = np.load(path)\n",
    "  print(\" [*] load %s\" % path)\n",
    "  return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "020c29fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] load ./resource/vocab.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "490"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = load_pkl(DATA_PATH + '/vocab.pkl')\n",
    "TOTAL_NUM_CODES = len(vocab)\n",
    "TOTAL_NUM_CODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bca3f079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] load ./resource/data.pkl\n",
      " [*] load ./resource/label.pkl\n"
     ]
    }
   ],
   "source": [
    "data = load_pkl(DATA_PATH + '/data.pkl')\n",
    "label = load_pkl(DATA_PATH + '/label.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "68d92d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(data,label,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3bbf3be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191142\n",
      "191142\n"
     ]
    }
   ],
   "source": [
    "X_train_flat = [item for sublist in X_train for item in sublist]\n",
    "print(len(X_train_flat))\n",
    "y_train_flat = [item for sublist in y_train for item in sublist]\n",
    "print(len(y_train_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f2c07ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Dimensionality of the word vectors\n",
    "VEC_SIZE = 100\n",
    "# Ignores all words with total frequency lower than this\n",
    "MIN_COUNT = 10\n",
    "\n",
    "w2v_model = Word2Vec(X_train_flat, min_count=MIN_COUNT, vector_size=VEC_SIZE,workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e780de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embedded = [sum(w2v_model.wv[lst])/len(lst) if len(lst)>0 else np.zeros(VEC_SIZE) for lst in X_train_flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "48ad3ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191142"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "115c528f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=200)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(max_iter=200)\n",
    "logreg.fit(X_train_embedded,y_train_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5e2323fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48794\n",
      "48794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[35951,  1162],\n",
       "       [ 8783,  2898]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_flat = [item for sublist in X_test for item in sublist]\n",
    "print(len(X_test_flat))\n",
    "y_test_flat = [item for sublist in y_test for item in sublist]\n",
    "print(len(y_test_flat))\n",
    "X_test_embedded = [sum(w2v_model.wv[lst])/len(lst) if len(lst)>0 else np.zeros(VEC_SIZE) for lst in X_test_flat]\n",
    "y_pred=logreg.predict(X_test_embedded)\n",
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(y_test_flat, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "84bd6ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7961839570438989\n",
      "Precision: 0.7137931034482758\n",
      "Recall: 0.2480951973289958\n",
      "F1: 0.368210405946255\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_flat, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test_flat, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test_flat, y_pred))\n",
    "print(\"F1:\",metrics.f1_score(y_test_flat, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cc5dca3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7588047358323263"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = logreg.predict_proba(X_test_embedded)[::,1]\n",
    "auc = metrics.roc_auc_score(y_test_flat, y_pred_proba)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec03983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
